[
  {
    "objectID": "approach/approach.html",
    "href": "approach/approach.html",
    "title": "Approach",
    "section": "",
    "text": "pacman::p_load(sf, tmap, tidyverse, sfdep, DT, patchwork, ggplot2)"
  },
  {
    "objectID": "approach/approach.html#data-wrangling",
    "href": "approach/approach.html#data-wrangling",
    "title": "Approach",
    "section": "2 Data Wrangling",
    "text": "2 Data Wrangling\n\n2.1 Geospatial Data\nTo create map plots, we require shape files of Thailand to create the boundaries of each state for map plotting. We used the dataset from HDX accessible here. As we wanted to analyse patterns across states, ADM1 is used.\n\nTH_ADM1<-st_read(dsn=\"data/geospatial/shapefiles\",\n                    layer=\"tha_admbnda_adm1_rtsd_20220121\") |> \n  st_transform(24047) |> #Since the coordinate reference system is not set to the CRS that thailand uses, we use st_transform to change it to Thailans CRS (24047).\n  arrange(ADM1_EN) |> \n  select(ADM1_EN, geometry)\n\nReading layer `tha_admbnda_adm1_rtsd_20220121' from data source \n  `/Users/pengyouyun/youyunpeng/lomocase/approach/data/geospatial/shapefiles' \n  using driver `ESRI Shapefile'\nSimple feature collection with 77 features and 16 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 97.34336 ymin: 5.613038 xmax: 105.637 ymax: 20.46507\nGeodetic CRS:  WGS 84\n\n\nA check for duplicates is done below:\n\nTH_ADM1$ADM1_EN[duplicated(TH_ADM1$ADM1_EN)==TRUE] #check for duplicates\n\ncharacter(0)\n\n\nSince there are no duplicates, we can continue with our analysis!\n\n\n2.2 Aspatial Data\nThe necessary datasets we are interested in are read into R’s environment below:\n\nconsumer_location<-read.csv(\"data/001_lomo_customers_dataset.csv\")\nproducts<-read_csv(\"data/004_lomo_products_dataset.csv\")\n\nRows: 32340 Columns: 9\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (2): product_id, product_category_name\ndbl (7): product_name_lenght, product_description_lenght, product_photos_qty...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nproducts_category<-read_csv(\"data/005_lomo_product_category_name_translation.csv\")\n\nRows: 71 Columns: 2\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (2): product_category_name_portugese, product_category_name_english\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nconsumer_orders<-read.csv(\"data/006_lomo_orders_dataset.csv\")\norder_items<-read_csv(\"data/007_lomo_order_items_dataset.csv\")\n\nRows: 112650 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (4): order_id, product_id, seller_id, shipping_limit_date\ndbl (3): order_item_id, price, freight_value\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\npayment<-read_csv(\"data/008_lomo_order_payments_dataset.csv\")\n\nRows: 103886 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (2): order_id, payment_type\ndbl (3): payment_sequential, payment_installments, payment_value\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nreviews<-read_csv(\"data/009_lomo_order_reviews_dataset.csv\")\n\nRows: 100000 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (6): review_id, order_id, review_comment_title, review_comment_message, ...\ndbl (1): review_score\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nFirst we want to create a dataframe that aggregates consumer orders and payment amount on a state level\n\nconsumer_orders_payment<-consumer_orders |> \n  inner_join(payment) #joining order and payment info\n\nJoining with `by = join_by(order_id)`\n\n\nWarning in inner_join(consumer_orders, payment): Each row in `x` is expected to match at most 1 row in `y`.\nℹ Row 1 of `x` matches multiple rows.\nℹ If multiple matches are expected, set `multiple = \"all\"` to silence this\n  warning.\n\n\nTo make sense of the data on a spatial level, we conduct another join with consumer_location to get the location of each order.\n\nconsumer_orders_location<-consumer_orders_payment |> \n  inner_join(consumer_location, by=\"customer_id\") |> \n  mutate(customer_state=as.factor(customer_state)) #create factor object for ease of plotting graphs\n\nsummary(consumer_orders_location)\n\n   order_id         customer_id        order_status      \n Length:103886      Length:103886      Length:103886     \n Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character  \n                                                         \n                                                         \n                                                         \n                                                         \n order_purchase_timestamp order_approved_at  order_delivered_carrier_date\n Length:103886            Length:103886      Length:103886               \n Class :character         Class :character   Class :character            \n Mode  :character         Mode  :character   Mode  :character            \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n order_delivered_customer_date order_estimated_delivery_date payment_sequential\n Length:103886                 Length:103886                 Min.   : 1.000    \n Class :character              Class :character              1st Qu.: 1.000    \n Mode  :character              Mode  :character              Median : 1.000    \n                                                             Mean   : 1.093    \n                                                             3rd Qu.: 1.000    \n                                                             Max.   :29.000    \n                                                                               \n payment_type       payment_installments payment_value      customer_unique_id\n Length:103886      Min.   : 0.000       Min.   :    0.00   Length:103886     \n Class :character   1st Qu.: 1.000       1st Qu.:   56.79   Class :character  \n Mode  :character   Median : 1.000       Median :  100.00   Mode  :character  \n                    Mean   : 2.853       Mean   :  154.10                     \n                    3rd Qu.: 4.000       3rd Qu.:  171.84                     \n                    Max.   :24.000       Max.   :13664.08                     \n                                                                              \n customer_zip_code_prefix customer_city                customer_state \n Length:103886            Length:103886      Roi Et           : 6474  \n Class :character         Class :character   Nakhon Ratchasima: 5818  \n Mode  :character         Mode  :character   Sakon Nakhon     : 5323  \n                                             Si Sa Ket        : 4997  \n                                             Maha Sarakham    : 4375  \n                                             Ubon Ratchathani : 4223  \n                                             (Other)          :72676  \n\n\nWe are interested to see, at the state level, what are number of orders, average payment and total payment statistics. Using the summarise function, we create a new dataframe for analysis:\n\ncount_location_state<-consumer_orders_location |> \n  group_by(customer_state) |> \n  summarise(no_orders=n(), ave_payment=mean(payment_value), total_payment=sum(payment_value))  |> \n  rename(ADM1_EN=customer_state)\n\ndatatable(count_location_state)\n\n\n\n\n\n\nOur second aspatial dataframe focuses on product specific data. We first obtain the translated product categories by conducting a join betweem “products” and “product_category” we reassign “products” to this data frame.\n\nproducts<-products |> \n  inner_join(products_category,by=c(\"product_category_name\"=\"product_category_name_portugese\")) |> \n  select(product_id, product_category_name_english) |> \n  mutate(product_category_name_english=as.factor(product_category_name_english))\n\nNext, we map review and product information to the order dataset\n\nproduct_order_reviews<-order_items |> \n  left_join(products, by=\"product_id\") |> \n  left_join(reviews, by=\"order_id\")\n\nWarning in left_join(left_join(order_items, products, by = \"product_id\"), : Each row in `x` is expected to match at most 1 row in `y`.\nℹ Row 96 of `x` matches multiple rows.\nℹ If multiple matches are expected, set `multiple = \"all\"` to silence this\n  warning.\n\n\nUsing summarise, we group the dataset via product category and obtain key statistics from the data (no_orders, ave_review, ave_price, total_price).\n\nproduct_order_reviews_summary<-product_order_reviews |> \n  group_by(product_category_name_english) |> \n  summarise(no_orders=n(), ave_review=mean(review_score), ave_price=mean(price), total_price=sum(price)) |> \n  arrange(desc(total_price))\n\ndatatable(product_order_reviews_summary)\n\n\n\n\n\n\nWe can include the location dimension by conducting a join with “consumer_orders_location” previously created\n\nproduct_order_reviews_location<-product_order_reviews |> \n  left_join(consumer_orders_location, by=\"order_id\")\n\nWarning in left_join(product_order_reviews, consumer_orders_location, by = \"order_id\"): Each row in `x` is expected to match at most 1 row in `y`.\nℹ Row 39 of `x` matches multiple rows.\nℹ If multiple matches are expected, set `multiple = \"all\"` to silence this\n  warning."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "1 + 1\n\n[1] 2"
  },
  {
    "objectID": "problemstatement/problemstatement.html",
    "href": "problemstatement/problemstatement.html",
    "title": "Problem Statement",
    "section": "",
    "text": "LoMo is a department store in Portugal and its online operations focus is on a B2B2C model. Small businesses across the country can leverage the platform to connect with customers and utilise its logistics partners to close the loop. For the context of this exercise, we will focus only on the customer side of the business.\nProcesses that are involved in its operations in fulfilling customer orders are highlighted below\n\nCustomer makes a purchase\nSeller is notified to fulfill order\nCustomer receives goods/estimated delivery date is due, a satisfaction survey is pushed\n\nLoMo has decided to enter Asia Pacific in 2015, selecting Thailand as its first entry point.\nThe problem statements are stated below:\n\nWhich product category has the best performance and which has the highest potential?\nIf you were the Chief Marketing Officer, how would you prioritise your (2C) marketing efforts? Would your strategy differ by region (state)? (Visualising your points on a map would help)"
  },
  {
    "objectID": "problemstatement/problemstatement.html#approach",
    "href": "problemstatement/problemstatement.html#approach",
    "title": "Problem Statement",
    "section": "2 Approach",
    "text": "2 Approach\nIn answering the two questions, we conduct our analysis on both aggregate and state-level.\n\n\n\n\n\n\n\nProblem Statement\nSub Questions\n\n\n\n\nWhich product category has the best performance and which has the highest potential?\nOn an aggregate level:\n\nwhich product categories had the highest order count, revenue generated, revenue/order generated, average reviews\n\nOn the state-level:\n\nSpecific to any selected product, are there specific states that performed better in these statistics\nWhen evaluating the state-level performance, is there spatial clustering in the level of performance\n\n\n\nIf you were the Chief Marketing Officer, how would you prioritise your (2C) marketing efforts? Would your strategy differ by region (state)? (Visualising your points on a map would help)\nOn the state level:\n\nWhich states had the highest order count, revenue generated, revenue/order generated, average reviews\nWhen evaluating the state-level performance, is there spatial clustering in the level of performance\n\n\n\n\nTherefore, we are answering the following questions\n\nWhich states should Lomo focus on (with high value consumers)\nWhich product categories on the aggregate level are the best performing\nIf Lomo is looking at a specific product category, which states should Lomo focus their marketing efforts on"
  },
  {
    "objectID": "approach/approach.html#exploratory-data-analysis",
    "href": "approach/approach.html#exploratory-data-analysis",
    "title": "Approach",
    "section": "3 Exploratory Data analysis",
    "text": "3 Exploratory Data analysis\n\n3.1 Aggregate\nLets create 3 chloropleth maps corresponding to the different\n\ncount_location_state_geometry<-count_location_state |> \n  inner_join(TH_ADM1, by=\"ADM1_EN\") |> \n  st_as_sf()\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\nplot_total_payment<-tm_shape(count_location_state_geometry |> \n           select(ADM1_EN, total_payment, geometry))+\n  tm_fill(\"total_payment\",\n          n=6,\n          style=\"equal\",\n          palette=\"Blues\")+\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title=paste(\"Distribution of total payment\"), \n            main.title.position=\"center\",\n            main.title.size = 0.8,\n            frame=TRUE)+\n  tm_scale_bar()+\n  tm_grid(alpha=0.2)\n\nplot_ave_payment<-tm_shape(count_location_state_geometry |> \n           select(ADM1_EN, ave_payment, geometry))+\n  tm_fill(\"ave_payment\",\n          n=6,\n          style=\"equal\",\n          palette=\"Blues\")+\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title=paste(\"Distribution of ave payment\"), \n            main.title.position=\"center\",\n            main.title.size = 0.8,\n            frame=TRUE)+\n  tm_scale_bar()+\n  tm_grid(alpha=0.2)\n\nplot_no_orders<-tm_shape(count_location_state_geometry |> \n           select(ADM1_EN, no_orders, geometry))+\n  tm_fill(\"no_orders\",\n          n=6,\n          style=\"equal\",\n          palette=\"Blues\")+\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title=paste(\"Distribution of no payment\"), \n            main.title.position=\"center\",\n            main.title.size = 0.8,\n            frame=TRUE)+\n  tm_scale_bar()+\n  tm_grid(alpha=0.2)\n\nplot_ave_payment\n\nLegend labels were too wide. The labels have been resized to 0.61, 0.61, 0.61, 0.61, 0.61, 0.61. Increase legend.width (argument of tm_layout) to make the legend wider and therefore the labels larger.\n\n\n\n\nplot_total_payment\n\nLegend labels were too wide. The labels have been resized to 0.48, 0.45, 0.45, 0.45, 0.45, 0.41. Increase legend.width (argument of tm_layout) to make the legend wider and therefore the labels larger.\n\n\n\n\nplot_no_orders\n\nSome legend labels were too wide. These labels have been resized to 0.61, 0.61, 0.61, 0.61, 0.61. Increase legend.width (argument of tm_layout) to make the legend wider and therefore the labels larger.\n\n\n\n\n\nGiven that the aggregated data would have more data points, we can conduct some statistical analysis on the possibility of clustering of these results.\n\n\n3.2 Products\nWith the dataset in place, we can now create a shiny app to loop through the different products and indicators that the user wants to focus on. We first try to create a prototype with the inputs “cool_stuff” as the product category and “no_orders” as the indicator\n\nproduct_order_reviews_location<-product_order_reviews |> \n  left_join(consumer_orders_location, by=\"order_id\") |>\n  group_by(product_category_name_english, customer_state) |> \n  summarise(no_orders=n(), total_price=sum(price), ave_price=mean(price)) |> \n  rename(ADM1_EN=customer_state) |> \n  right_join(TH_ADM1, by=\"ADM1_EN\") |> \n  st_as_sf()\n\nWarning in left_join(product_order_reviews, consumer_orders_location, by = \"order_id\"): Each row in `x` is expected to match at most 1 row in `y`.\nℹ Row 39 of `x` matches multiple rows.\nℹ If multiple matches are expected, set `multiple = \"all\"` to silence this\n  warning.\n\n\n`summarise()` has grouped output by 'product_category_name_english'. You can\noverride using the `.groups` argument.\n\ni=\"cool_stuff\"\nj=\"no_orders\"\n\n# create tmap plot\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\ntm_shape(product_order_reviews_location |> \n           filter(product_category_name_english==i) |> \n           select(ADM1_EN, j, geometry))+\n  tm_fill(j,\n          n=6,\n          style=\"equal\",\n          palette=\"Blues\")+\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title=paste(j, \"for\", i), \n            main.title.position=\"center\",\n            main.title.size=1.2,\n            legend.height=0.45,\n            legend.width = 0.35,\n            frame=TRUE)+\n  tm_scale_bar()+\n  tm_grid(alpha=0.2)\n\nWarning: Using an external vector in selections was deprecated in tidyselect 1.1.0.\nℹ Please use `all_of()` or `any_of()` instead.\n  # Was:\n  data %>% select(j)\n\n  # Now:\n  data %>% select(all_of(j))\n\nSee <https://tidyselect.r-lib.org/reference/faq-external-vector.html>.\n\n\nLegend labels were too wide. The labels have been resized to 0.64, 0.58, 0.53, 0.48, 0.48, 0.48. Increase legend.width (argument of tm_layout) to make the legend wider and therefore the labels larger.\n\n\n\n\n\nA simple Shiny App can be created:\n\nlibrary(shiny)\nproduct_list<-unique(product_order_reviews_location$product_category_name_english)\n\n# Define the UI\nui <- fluidPage(\n  selectInput(\n    \"indicator\",\n    label=\"pick an indicator\",\n    choices=c(\"no_orders\", \"ave_price\",\"total_price\"),\n    selected=\"no_orders\",\n    multiple=FALSE\n  ),\n  selectInput(\n    \"product\",\n    label=\"pick a product category\",\n    choices=product_list,\n    selected=\"cool_stuff\",\n    multiple=FALSE\n  ),\n  # Create a tmap output element\n  tmapOutput(\"my_map\"),\n  DT::dataTableOutput(outputId = \"my_table\")\n)\n\n# Define the server\nserver <- function(input, output) {\n  dataset<-reactive({\n    product_order_reviews_location |>\n      filter(product_category_name_english==input$product) |> \n      select(ADM1_EN, input$indicator, geometry)\n  })\n  # Render the tmap in the output element\n  output$my_map <- renderTmap({\n    # Create the tmap\n    tm_shape(shp=dataset())+\n      tm_fill(input$indicator,\n          style=\"quantile\",\n          palette=\"Blues\")\n  })\n  \n  output$my_table<-DT::renderDataTable({\n    DT::datatable(data=dataset())\n  })\n}\n\n# Run the app\nshinyApp(ui, server)"
  },
  {
    "objectID": "approach/approach.html#a-more-generic-analysis-of-products",
    "href": "approach/approach.html#a-more-generic-analysis-of-products",
    "title": "Approach",
    "section": "4 A more generic analysis of products",
    "text": "4 A more generic analysis of products\nTime analysis:\n\ni=\"health_beauty\"\nj=\"no_order\"\n\nspecific_product_time<-product_order_reviews |> \n  mutate(shipping_limit_date=as.Date(shipping_limit_date, format = \"%d/%m/%Y\")) |> \n  mutate(shipping_month=as.Date(format(shipping_limit_date, \"%Y-%m-01\"))) |> \n  filter(product_category_name_english==i, \n         shipping_month!=\"2018-09-01\") |> #remove due to incomplete dataset to represent sales of the month\n  select(price, product_category_name_english, shipping_month) |> \n  group_by(shipping_month) |> \n  summarise(no_order=n(), total_price=sum(price))\n\n#fitting linear model and extracting slope of line\ncoef(lm(no_order~shipping_month, data=specific_product_time))[\"shipping_month\"] |> \n  as.numeric()\n\n[1] 1.353922\n\nggplot(specific_product_time,aes(x=shipping_month, y=no_order))+\n  geom_point()+\n  geom_smooth(method = \"lm\", se = FALSE)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\nggplot(specific_product_time,aes(x=shipping_month, y=total_price))+\n  geom_point()+\n  geom_smooth(method = \"lm\", se = FALSE)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\nWe can create 2 functions to obtain the slopes for no_order and total price below:\n\ndetermine_slope_no_order <- function(product) {\n  \n  specific_product_time<-product_order_reviews |> \n  mutate(shipping_limit_date=as.Date(shipping_limit_date, format = \"%d/%m/%Y\")) |> \n  mutate(shipping_month=as.Date(format(shipping_limit_date, \"%Y-%m-01\"))) |> \n  filter(product_category_name_english==product, \n         shipping_month!=\"2018-09-01\") |> #remove due to incomplete dataset to represent sales of the month\n  select(price, product_category_name_english, shipping_month) |> \n  group_by(shipping_month) |> \n  summarise(no_order=n(), total_price=sum(price))\n  \n  slope<-coef(lm(no_order~shipping_month, data=specific_product_time))[\"shipping_month\"] |> \n  as.numeric()\n  \n  result <- ifelse(is.na(slope), 0, slope)\n  \n  return(result)\n}\n\ndetermine_slope_total_price <- function(product) {\n  \n  specific_product_time<-product_order_reviews |> \n  mutate(shipping_limit_date=as.Date(shipping_limit_date, format = \"%d/%m/%Y\")) |> \n  mutate(shipping_month=as.Date(format(shipping_limit_date, \"%Y-%m-01\"))) |> \n  filter(product_category_name_english==product, \n         shipping_month!=\"2018-09-01\") |> #remove due to incomplete dataset to represent sales of the month\n  select(price, product_category_name_english, shipping_month) |> \n  group_by(shipping_month) |> \n  summarise(no_order=n(), total_price=sum(price))\n  \n  slope<-coef(lm(total_price~shipping_month, data=specific_product_time))[\"shipping_month\"] |> \n  as.numeric()\n  \n  result <- ifelse(is.na(slope), 0, slope)\n  \n  return(result)\n}\n\ndetermine_slope_no_order(\"fashion_children_clothes\")\n\n[1] 0.001067827\n\ndetermine_slope_total_price(\"fashion_children_clothes\")\n\n[1] -0.03939796\n\n\nNow, we can initialise an empty dataframe with all of the product names and loop this function through all products.\n\nproduct_list<-unique(product_order_reviews_location$product_category_name_english) #previously created\n\ndf<-data.frame(product_list, 0, 0) |> \n  rename(slope_no_order=X0, slope_total_price=X0.1)\n\nfor (i in product_list){\n  slope_no_order=determine_slope_no_order(i)\n  slope_total_price=determine_slope_total_price(i)\n  df <- rbind(df, data.frame(product_list = i, slope_no_order = slope_no_order, slope_total_price = slope_total_price))\n}\n\ndf"
  }
]