---
title: "Approach"
date-modified: "`r Sys.Date()`"
number-sections: true
format:
  html:
    code-tools: true
editor: visual
---

## Installing packages

```{r}
pacman::p_load(sf, tmap, tidyverse, sfdep, DT, patchwork, ggplot2)
```

## Data Wrangling

### Geospatial Data

To create map plots, we require shape files of Thailand to create the boundaries of each state for map plotting. We used the dataset from HDX accessible [here](https://data.humdata.org/dataset/cod-ab-tha?). As we wanted to analyse patterns across states, ADM1 is used.

```{r}
TH_ADM1<-st_read(dsn="data/geospatial/shapefiles",
                    layer="tha_admbnda_adm1_rtsd_20220121") |> 
  st_transform(24047) |> #Since the coordinate reference system is not set to the CRS that thailand uses, we use st_transform to change it to Thailans CRS (24047).
  arrange(ADM1_EN) |> 
  select(ADM1_EN, geometry)
```

A check for duplicates is done below:

```{r}
TH_ADM1$ADM1_EN[duplicated(TH_ADM1$ADM1_EN)==TRUE] #check for duplicates
```

Since there are no duplicates, we can continue with our analysis!

### Aspatial Data

The necessary datasets we are interested in are read into R's environment below:

```{r}
consumer_location<-read.csv("data/001_lomo_customers_dataset.csv")
products<-read_csv("data/004_lomo_products_dataset.csv")
products_category<-read_csv("data/005_lomo_product_category_name_translation.csv")
consumer_orders<-read.csv("data/006_lomo_orders_dataset.csv")
order_items<-read_csv("data/007_lomo_order_items_dataset.csv")
payment<-read_csv("data/008_lomo_order_payments_dataset.csv")
reviews<-read_csv("data/009_lomo_order_reviews_dataset.csv")
```

First we want to create a dataframe that aggregates consumer orders and payment amount on a state level

```{r}
consumer_orders_payment<-consumer_orders |> 
  inner_join(payment) #joining order and payment info
```

To make sense of the data on a spatial level, we conduct another join with consumer_location to get the location of each order.

```{r}
consumer_orders_location<-consumer_orders_payment |> 
  inner_join(consumer_location, by="customer_id") |> 
  mutate(customer_state=as.factor(customer_state)) #create factor object for ease of plotting graphs

summary(consumer_orders_location)
```

We are interested to see, at the state level, what are number of orders, average payment and total payment statistics. Using the summarise function, we create a new dataframe for analysis:

```{r}
count_location_state<-consumer_orders_location |> 
  group_by(customer_state) |> 
  summarise(no_orders=n(), ave_payment=mean(payment_value), total_payment=sum(payment_value))  |> 
  rename(ADM1_EN=customer_state)

datatable(count_location_state)
```

Our second aspatial dataframe focuses on product specific data. We first obtain the translated product categories by conducting a join betweem "products" and "product_category" we reassign "products" to this data frame.

```{r}
products<-products |> 
  inner_join(products_category,by=c("product_category_name"="product_category_name_portugese")) |> 
  select(product_id, product_category_name_english) |> 
  mutate(product_category_name_english=as.factor(product_category_name_english))
```

Next, we map review and product information to the order dataset

```{r}
product_order_reviews<-order_items |> 
  left_join(products, by="product_id") |> 
  left_join(reviews, by="order_id")
```

Using summarise, we group the dataset via product category and obtain key statistics from the data (no_orders, ave_review, ave_price, total_price).

```{r}
product_order_reviews_summary<-product_order_reviews |> 
  group_by(product_category_name_english) |> 
  summarise(no_orders=n(), ave_review=mean(review_score), ave_price=mean(price), total_price=sum(price)) |> 
  arrange(desc(total_price))

datatable(product_order_reviews_summary)
```

We can include the location dimension by conducting a join with "consumer_orders_location" previously created

```{r}
product_order_reviews_location<-product_order_reviews |> 
  left_join(consumer_orders_location, by="order_id")
```
## Exploratory Data analysis

### Aggregate

Lets create 3 chloropleth maps corresponding to the different

```{r}
count_location_state_geometry<-count_location_state |> 
  inner_join(TH_ADM1, by="ADM1_EN") |> 
  st_as_sf()

tmap_mode("plot")
plot_total_payment<-tm_shape(count_location_state_geometry |> 
           select(ADM1_EN, total_payment, geometry))+
  tm_fill("total_payment",
          n=6,
          style="equal",
          palette="Blues")+
  tm_borders(alpha = 0.5) +
  tm_layout(main.title=paste("Distribution of total payment"), 
            main.title.position="center",
            main.title.size = 0.8,
            frame=TRUE)+
  tm_scale_bar()+
  tm_grid(alpha=0.2)

plot_ave_payment<-tm_shape(count_location_state_geometry |> 
           select(ADM1_EN, ave_payment, geometry))+
  tm_fill("ave_payment",
          n=6,
          style="equal",
          palette="Blues")+
  tm_borders(alpha = 0.5) +
  tm_layout(main.title=paste("Distribution of ave payment"), 
            main.title.position="center",
            main.title.size = 0.8,
            frame=TRUE)+
  tm_scale_bar()+
  tm_grid(alpha=0.2)

plot_no_orders<-tm_shape(count_location_state_geometry |> 
           select(ADM1_EN, no_orders, geometry))+
  tm_fill("no_orders",
          n=6,
          style="equal",
          palette="Blues")+
  tm_borders(alpha = 0.5) +
  tm_layout(main.title=paste("Distribution of no payment"), 
            main.title.position="center",
            main.title.size = 0.8,
            frame=TRUE)+
  tm_scale_bar()+
  tm_grid(alpha=0.2)

plot_ave_payment
plot_total_payment
plot_no_orders
```

Given that the aggregated data would have more data points, we can conduct some statistical analysis on the possibility of clustering of these results.

### Products

With the dataset in place, we can now create a shiny app to loop through the different products and indicators that the user wants to focus on. We first try to create a prototype with the inputs "cool_stuff" as the product category and "no_orders" as the indicator

```{r}
product_order_reviews_location<-product_order_reviews |> 
  left_join(consumer_orders_location, by="order_id") |>
  group_by(product_category_name_english, customer_state) |> 
  summarise(no_orders=n(), total_price=sum(price), ave_price=mean(price)) |> 
  rename(ADM1_EN=customer_state) |> 
  right_join(TH_ADM1, by="ADM1_EN") |> 
  st_as_sf()

i="cool_stuff"
j="no_orders"

# create tmap plot
tmap_mode("plot")
tm_shape(product_order_reviews_location |> 
           filter(product_category_name_english==i) |> 
           select(ADM1_EN, j, geometry))+
  tm_fill(j,
          n=6,
          style="equal",
          palette="Blues")+
  tm_borders(alpha = 0.5) +
  tm_layout(main.title=paste(j, "for", i), 
            main.title.position="center",
            main.title.size=1.2,
            legend.height=0.45,
            legend.width = 0.35,
            frame=TRUE)+
  tm_scale_bar()+
  tm_grid(alpha=0.2)
```

A simple Shiny App can be created:

```{r eval=FALSE}
library(shiny)
product_list<-unique(product_order_reviews_location$product_category_name_english)

# Define the UI
ui <- fluidPage(
  selectInput(
    "indicator",
    label="pick an indicator",
    choices=c("no_orders", "ave_price","total_price"),
    selected="no_orders",
    multiple=FALSE
  ),
  selectInput(
    "product",
    label="pick a product category",
    choices=product_list,
    selected="cool_stuff",
    multiple=FALSE
  ),
  # Create a tmap output element
  tmapOutput("my_map"),
  DT::dataTableOutput(outputId = "my_table")
)

# Define the server
server <- function(input, output) {
  dataset<-reactive({
    product_order_reviews_location |>
      filter(product_category_name_english==input$product) |> 
      select(ADM1_EN, input$indicator, geometry)
  })
  # Render the tmap in the output element
  output$my_map <- renderTmap({
    # Create the tmap
    tm_shape(shp=dataset())+
      tm_fill(input$indicator,
          style="quantile",
          palette="Blues")
  })
  
  output$my_table<-DT::renderDataTable({
    DT::datatable(data=dataset())
  })
}

# Run the app
shinyApp(ui, server)
```

## A more generic analysis of products
Time analysis:
```{r}
i="health_beauty"
j="no_order"

specific_product_time<-product_order_reviews |> 
  mutate(shipping_limit_date=as.Date(shipping_limit_date, format = "%d/%m/%Y")) |> 
  mutate(shipping_month=as.Date(format(shipping_limit_date, "%Y-%m-01"))) |> 
  filter(product_category_name_english==i, 
         shipping_month!="2018-09-01") |> #remove due to incomplete dataset to represent sales of the month
  select(price, product_category_name_english, shipping_month) |> 
  group_by(shipping_month) |> 
  summarise(no_order=n(), total_price=sum(price))

#fitting linear model and extracting slope of line
coef(lm(no_order~shipping_month, data=specific_product_time))["shipping_month"] |> 
  as.numeric()

ggplot(specific_product_time,aes(x=shipping_month, y=no_order))+
  geom_point()+
  geom_smooth(method = "lm", se = FALSE)

ggplot(specific_product_time,aes(x=shipping_month, y=total_price))+
  geom_point()+
  geom_smooth(method = "lm", se = FALSE)
```

We can create 2 functions to obtain the slopes for no_order and total price below:
```{r} 
determine_slope_no_order <- function(product) {
  
  specific_product_time<-product_order_reviews |> 
  mutate(shipping_limit_date=as.Date(shipping_limit_date, format = "%d/%m/%Y")) |> 
  mutate(shipping_month=as.Date(format(shipping_limit_date, "%Y-%m-01"))) |> 
  filter(product_category_name_english==product, 
         shipping_month!="2018-09-01") |> #remove due to incomplete dataset to represent sales of the month
  select(price, product_category_name_english, shipping_month) |> 
  group_by(shipping_month) |> 
  summarise(no_order=n(), total_price=sum(price))
  
  slope<-coef(lm(no_order~shipping_month, data=specific_product_time))["shipping_month"] |> 
  as.numeric()
  
  result <- ifelse(is.na(slope), 0, slope)
  
  return(result)
}

determine_slope_total_price <- function(product) {
  
  specific_product_time<-product_order_reviews |> 
  mutate(shipping_limit_date=as.Date(shipping_limit_date, format = "%d/%m/%Y")) |> 
  mutate(shipping_month=as.Date(format(shipping_limit_date, "%Y-%m-01"))) |> 
  filter(product_category_name_english==product, 
         shipping_month!="2018-09-01") |> #remove due to incomplete dataset to represent sales of the month
  select(price, product_category_name_english, shipping_month) |> 
  group_by(shipping_month) |> 
  summarise(no_order=n(), total_price=sum(price))
  
  slope<-coef(lm(total_price~shipping_month, data=specific_product_time))["shipping_month"] |> 
  as.numeric()
  
  result <- ifelse(is.na(slope), 0, slope)
  
  return(result)
}

determine_slope_no_order("fashion_children_clothes")
determine_slope_total_price("fashion_children_clothes")
```

Now, we can initialise an empty dataframe with all of the product names and loop this function through all products.
```{r eval=FALSE}
product_list<-unique(product_order_reviews_location$product_category_name_english) #previously created

df<-data.frame(product_list, 0, 0) |> 
  rename(slope_no_order=X0, slope_total_price=X0.1)

for (i in product_list){
  slope_no_order=determine_slope_no_order(i)
  slope_total_price=determine_slope_total_price(i)
  df <- rbind(df, data.frame(product_list = i, slope_no_order = slope_no_order, slope_total_price = slope_total_price))
}

df
```




